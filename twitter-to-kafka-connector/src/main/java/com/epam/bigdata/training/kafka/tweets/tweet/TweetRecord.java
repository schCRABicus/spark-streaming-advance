/**
 * Autogenerated by Avro
 *
 * DO NOT EDIT DIRECTLY
 */
package com.epam.bigdata.training.kafka.tweets.tweet;

import org.apache.avro.specific.SpecificData;
import org.apache.avro.message.BinaryMessageEncoder;
import org.apache.avro.message.BinaryMessageDecoder;
import org.apache.avro.message.SchemaStore;

@SuppressWarnings("all")
@org.apache.avro.specific.AvroGenerated
public class TweetRecord extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
  private static final long serialVersionUID = 4052189961449276980L;
  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"TweetRecord\",\"namespace\":\"com.epam.bigdata.training.kafka.tweets.tweet\",\"fields\":[{\"name\":\"dt\",\"type\":\"long\"},{\"name\":\"id\",\"type\":\"long\"},{\"name\":\"text\",\"type\":\"string\"},{\"name\":\"hashtags\",\"type\":{\"type\":\"array\",\"items\":\"string\"}}]}");
  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }

  private static SpecificData MODEL$ = new SpecificData();

  private static final BinaryMessageEncoder<TweetRecord> ENCODER =
      new BinaryMessageEncoder<TweetRecord>(MODEL$, SCHEMA$);

  private static final BinaryMessageDecoder<TweetRecord> DECODER =
      new BinaryMessageDecoder<TweetRecord>(MODEL$, SCHEMA$);

  /**
   * Return the BinaryMessageDecoder instance used by this class.
   */
  public static BinaryMessageDecoder<TweetRecord> getDecoder() {
    return DECODER;
  }

  /**
   * Create a new BinaryMessageDecoder instance for this class that uses the specified {@link SchemaStore}.
   * @param resolver a {@link SchemaStore} used to find schemas by fingerprint
   */
  public static BinaryMessageDecoder<TweetRecord> createDecoder(SchemaStore resolver) {
    return new BinaryMessageDecoder<TweetRecord>(MODEL$, SCHEMA$, resolver);
  }

  /** Serializes this TweetRecord to a ByteBuffer. */
  public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException {
    return ENCODER.encode(this);
  }

  /** Deserializes a TweetRecord from a ByteBuffer. */
  public static TweetRecord fromByteBuffer(
      java.nio.ByteBuffer b) throws java.io.IOException {
    return DECODER.decode(b);
  }

  @Deprecated public long dt;
  @Deprecated public long id;
  @Deprecated public java.lang.CharSequence text;
  @Deprecated public java.util.List<java.lang.CharSequence> hashtags;

  /**
   * Default constructor.  Note that this does not initialize fields
   * to their default values from the schema.  If that is desired then
   * one should use <code>newBuilder()</code>.
   */
  public TweetRecord() {}

  /**
   * All-args constructor.
   * @param dt The new value for dt
   * @param id The new value for id
   * @param text The new value for text
   * @param hashtags The new value for hashtags
   */
  public TweetRecord(java.lang.Long dt, java.lang.Long id, java.lang.CharSequence text, java.util.List<java.lang.CharSequence> hashtags) {
    this.dt = dt;
    this.id = id;
    this.text = text;
    this.hashtags = hashtags;
  }

  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
  // Used by DatumWriter.  Applications should not call.
  public java.lang.Object get(int field$) {
    switch (field$) {
    case 0: return dt;
    case 1: return id;
    case 2: return text;
    case 3: return hashtags;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  // Used by DatumReader.  Applications should not call.
  @SuppressWarnings(value="unchecked")
  public void put(int field$, java.lang.Object value$) {
    switch (field$) {
    case 0: dt = (java.lang.Long)value$; break;
    case 1: id = (java.lang.Long)value$; break;
    case 2: text = (java.lang.CharSequence)value$; break;
    case 3: hashtags = (java.util.List<java.lang.CharSequence>)value$; break;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  /**
   * Gets the value of the 'dt' field.
   * @return The value of the 'dt' field.
   */
  public java.lang.Long getDt() {
    return dt;
  }

  /**
   * Sets the value of the 'dt' field.
   * @param value the value to set.
   */
  public void setDt(java.lang.Long value) {
    this.dt = value;
  }

  /**
   * Gets the value of the 'id' field.
   * @return The value of the 'id' field.
   */
  public java.lang.Long getId() {
    return id;
  }

  /**
   * Sets the value of the 'id' field.
   * @param value the value to set.
   */
  public void setId(java.lang.Long value) {
    this.id = value;
  }

  /**
   * Gets the value of the 'text' field.
   * @return The value of the 'text' field.
   */
  public java.lang.CharSequence getText() {
    return text;
  }

  /**
   * Sets the value of the 'text' field.
   * @param value the value to set.
   */
  public void setText(java.lang.CharSequence value) {
    this.text = value;
  }

  /**
   * Gets the value of the 'hashtags' field.
   * @return The value of the 'hashtags' field.
   */
  public java.util.List<java.lang.CharSequence> getHashtags() {
    return hashtags;
  }

  /**
   * Sets the value of the 'hashtags' field.
   * @param value the value to set.
   */
  public void setHashtags(java.util.List<java.lang.CharSequence> value) {
    this.hashtags = value;
  }

  /**
   * Creates a new TweetRecord RecordBuilder.
   * @return A new TweetRecord RecordBuilder
   */
  public static com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder newBuilder() {
    return new com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder();
  }

  /**
   * Creates a new TweetRecord RecordBuilder by copying an existing Builder.
   * @param other The existing builder to copy.
   * @return A new TweetRecord RecordBuilder
   */
  public static com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder newBuilder(com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder other) {
    return new com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder(other);
  }

  /**
   * Creates a new TweetRecord RecordBuilder by copying an existing TweetRecord instance.
   * @param other The existing instance to copy.
   * @return A new TweetRecord RecordBuilder
   */
  public static com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder newBuilder(com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord other) {
    return new com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder(other);
  }

  /**
   * RecordBuilder for TweetRecord instances.
   */
  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<TweetRecord>
    implements org.apache.avro.data.RecordBuilder<TweetRecord> {

    private long dt;
    private long id;
    private java.lang.CharSequence text;
    private java.util.List<java.lang.CharSequence> hashtags;

    /** Creates a new Builder */
    private Builder() {
      super(SCHEMA$);
    }

    /**
     * Creates a Builder by copying an existing Builder.
     * @param other The existing Builder to copy.
     */
    private Builder(com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder other) {
      super(other);
      if (isValidValue(fields()[0], other.dt)) {
        this.dt = data().deepCopy(fields()[0].schema(), other.dt);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.id)) {
        this.id = data().deepCopy(fields()[1].schema(), other.id);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.text)) {
        this.text = data().deepCopy(fields()[2].schema(), other.text);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.hashtags)) {
        this.hashtags = data().deepCopy(fields()[3].schema(), other.hashtags);
        fieldSetFlags()[3] = true;
      }
    }

    /**
     * Creates a Builder by copying an existing TweetRecord instance
     * @param other The existing instance to copy.
     */
    private Builder(com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord other) {
            super(SCHEMA$);
      if (isValidValue(fields()[0], other.dt)) {
        this.dt = data().deepCopy(fields()[0].schema(), other.dt);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.id)) {
        this.id = data().deepCopy(fields()[1].schema(), other.id);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.text)) {
        this.text = data().deepCopy(fields()[2].schema(), other.text);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.hashtags)) {
        this.hashtags = data().deepCopy(fields()[3].schema(), other.hashtags);
        fieldSetFlags()[3] = true;
      }
    }

    /**
      * Gets the value of the 'dt' field.
      * @return The value.
      */
    public java.lang.Long getDt() {
      return dt;
    }

    /**
      * Sets the value of the 'dt' field.
      * @param value The value of 'dt'.
      * @return This builder.
      */
    public com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder setDt(long value) {
      validate(fields()[0], value);
      this.dt = value;
      fieldSetFlags()[0] = true;
      return this;
    }

    /**
      * Checks whether the 'dt' field has been set.
      * @return True if the 'dt' field has been set, false otherwise.
      */
    public boolean hasDt() {
      return fieldSetFlags()[0];
    }


    /**
      * Clears the value of the 'dt' field.
      * @return This builder.
      */
    public com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder clearDt() {
      fieldSetFlags()[0] = false;
      return this;
    }

    /**
      * Gets the value of the 'id' field.
      * @return The value.
      */
    public java.lang.Long getId() {
      return id;
    }

    /**
      * Sets the value of the 'id' field.
      * @param value The value of 'id'.
      * @return This builder.
      */
    public com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder setId(long value) {
      validate(fields()[1], value);
      this.id = value;
      fieldSetFlags()[1] = true;
      return this;
    }

    /**
      * Checks whether the 'id' field has been set.
      * @return True if the 'id' field has been set, false otherwise.
      */
    public boolean hasId() {
      return fieldSetFlags()[1];
    }


    /**
      * Clears the value of the 'id' field.
      * @return This builder.
      */
    public com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder clearId() {
      fieldSetFlags()[1] = false;
      return this;
    }

    /**
      * Gets the value of the 'text' field.
      * @return The value.
      */
    public java.lang.CharSequence getText() {
      return text;
    }

    /**
      * Sets the value of the 'text' field.
      * @param value The value of 'text'.
      * @return This builder.
      */
    public com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder setText(java.lang.CharSequence value) {
      validate(fields()[2], value);
      this.text = value;
      fieldSetFlags()[2] = true;
      return this;
    }

    /**
      * Checks whether the 'text' field has been set.
      * @return True if the 'text' field has been set, false otherwise.
      */
    public boolean hasText() {
      return fieldSetFlags()[2];
    }


    /**
      * Clears the value of the 'text' field.
      * @return This builder.
      */
    public com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder clearText() {
      text = null;
      fieldSetFlags()[2] = false;
      return this;
    }

    /**
      * Gets the value of the 'hashtags' field.
      * @return The value.
      */
    public java.util.List<java.lang.CharSequence> getHashtags() {
      return hashtags;
    }

    /**
      * Sets the value of the 'hashtags' field.
      * @param value The value of 'hashtags'.
      * @return This builder.
      */
    public com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder setHashtags(java.util.List<java.lang.CharSequence> value) {
      validate(fields()[3], value);
      this.hashtags = value;
      fieldSetFlags()[3] = true;
      return this;
    }

    /**
      * Checks whether the 'hashtags' field has been set.
      * @return True if the 'hashtags' field has been set, false otherwise.
      */
    public boolean hasHashtags() {
      return fieldSetFlags()[3];
    }


    /**
      * Clears the value of the 'hashtags' field.
      * @return This builder.
      */
    public com.epam.bigdata.training.kafka.tweets.tweet.TweetRecord.Builder clearHashtags() {
      hashtags = null;
      fieldSetFlags()[3] = false;
      return this;
    }

    @Override
    @SuppressWarnings("unchecked")
    public TweetRecord build() {
      try {
        TweetRecord record = new TweetRecord();
        record.dt = fieldSetFlags()[0] ? this.dt : (java.lang.Long) defaultValue(fields()[0]);
        record.id = fieldSetFlags()[1] ? this.id : (java.lang.Long) defaultValue(fields()[1]);
        record.text = fieldSetFlags()[2] ? this.text : (java.lang.CharSequence) defaultValue(fields()[2]);
        record.hashtags = fieldSetFlags()[3] ? this.hashtags : (java.util.List<java.lang.CharSequence>) defaultValue(fields()[3]);
        return record;
      } catch (java.lang.Exception e) {
        throw new org.apache.avro.AvroRuntimeException(e);
      }
    }
  }

  @SuppressWarnings("unchecked")
  private static final org.apache.avro.io.DatumWriter<TweetRecord>
    WRITER$ = (org.apache.avro.io.DatumWriter<TweetRecord>)MODEL$.createDatumWriter(SCHEMA$);

  @Override public void writeExternal(java.io.ObjectOutput out)
    throws java.io.IOException {
    WRITER$.write(this, SpecificData.getEncoder(out));
  }

  @SuppressWarnings("unchecked")
  private static final org.apache.avro.io.DatumReader<TweetRecord>
    READER$ = (org.apache.avro.io.DatumReader<TweetRecord>)MODEL$.createDatumReader(SCHEMA$);

  @Override public void readExternal(java.io.ObjectInput in)
    throws java.io.IOException {
    READER$.read(this, SpecificData.getDecoder(in));
  }

}
